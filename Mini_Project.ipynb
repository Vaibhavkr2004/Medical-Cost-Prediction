{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSxoRygsU8+WCXLWTPm+T7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_U3SDMVcrOZ",
        "outputId": "3aa62a45-a2ee-4fb7-ea0e-3ff105ca20d0",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-2-beb55f24d5ec>\", line 1, in <cell line: 0>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A48a44dc2qJ",
        "outputId": "46dc6ea8-ae03-4c35-e852-b85b7c94eea5",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: torchaudio==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-xla -f https://storage.googleapis.com/tpu-pytorch/wheels/colab.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K8wcx6-piy9_",
        "outputId": "541c028c-adc7-4ed5-db99-7c5945023026"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/tpu-pytorch/wheels/colab.html\n",
            "Collecting torch-xla\n",
            "  Downloading torch_xla-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch-xla) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-xla) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torch-xla) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-xla) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-xla) (2025.1.31)\n",
            "Downloading torch_xla-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl (93.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m93.6/93.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-xla\n",
            "Successfully installed torch-xla-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A46O97SLjUUA",
        "outputId": "73fff486-4da4-43da-f7c1-b5f50a94fab8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install transformers torch scikit-learn pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ‚úÖ Update paths based on Google Drive location\n",
        "human_dataset_path = \"/content/drive/MyDrive/Mini Project/HumanDataset.csv\"\n",
        "ai_dataset_path = \"/content/drive/MyDrive/Mini Project/AiDataset.csv\"\n",
        "\n",
        "# ‚úÖ Load datasets\n",
        "human_texts = pd.read_csv(human_dataset_path)\n",
        "ai_texts = pd.read_csv(ai_dataset_path)\n",
        "\n",
        "# ‚úÖ Ensure correct column names\n",
        "human_texts.columns = human_texts.columns.str.strip()\n",
        "ai_texts.columns = ai_texts.columns.str.strip()\n",
        "\n",
        "# ‚úÖ Check if \"text\" column exists\n",
        "if \"text\" not in human_texts.columns or \"text\" not in ai_texts.columns:\n",
        "    raise KeyError(\"Column 'text' not found in dataset. Check CSV files.\")\n",
        "\n",
        "# ‚úÖ Assign labels\n",
        "human_texts[\"label\"] = 0  # Human = 0\n",
        "ai_texts[\"label\"] = 1  # AI = 1\n",
        "\n",
        "# ‚úÖ Merge and shuffle dataset\n",
        "df = pd.concat([human_texts, ai_texts]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# ‚úÖ Print first 5 rows to confirm\n",
        "print(df.head())\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ‚úÖ Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# ‚úÖ Ensure df[\"text\"] is a list of strings\n",
        "df[\"text\"] = df[\"text\"].astype(str).fillna(\"\")  # Convert NaN to empty strings\n",
        "\n",
        "# ‚úÖ Split dataset\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ‚úÖ Ensure all texts are strings (avoid tokenizer errors)\n",
        "assert all(isinstance(text, str) for text in train_texts), \"‚ùå Error: train_texts contains non-string values!\"\n",
        "assert all(isinstance(text, str) for text in test_texts), \"‚ùå Error: test_texts contains non-string values!\"\n",
        "\n",
        "# ‚úÖ Create Dataset Class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(\n",
        "            texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n",
        "        )\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Ensure labels are LongTensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "# ‚úÖ Convert to PyTorch Dataset\n",
        "train_dataset = TextDataset(train_texts, train_labels)\n",
        "test_dataset = TextDataset(test_texts, test_labels)\n",
        "\n",
        "# ‚úÖ Create DataLoaders (Optimized for GPU)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, pin_memory=True)\n",
        "\n",
        "print(\"‚úÖ Data preprocessing completed successfully!\")\n",
        "\n",
        "!pip install opencv-python\n",
        "\n",
        "import os\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# ‚úÖ Check if a saved model exists\n",
        "if os.path.exists(\"/content/drive/MyDrive/saved_model\"):\n",
        "    print(\"‚úÖ Loading pre-trained model...\")\n",
        "    model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/saved_model\")\n",
        "else:\n",
        "    print(\"üöÄ No trained model found! Initializing new model.\")\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"‚úÖ Model is ready!\")\n",
        "\n",
        "import torch\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "# ‚úÖ Mount Google Drive path\n",
        "drive_path = \"/content/drive/My Drive/Mini Project/saved_model\"\n",
        "\n",
        "# ‚úÖ Initialize GradScaler correctly for PyTorch 2.0+\n",
        "scaler = torch.amp.GradScaler(\"cuda\")\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch = {key: val.to(\"cuda\") for key, val in batch.items()}  # Move batch to GPU\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # ‚úÖ Use correct AMP syntax\n",
        "            with torch.amp.autocast(device_type=\"cuda\"):\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"‚úÖ Epoch {epoch+1} completed | Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # ‚úÖ Save trained model in Google Drive\n",
        "    model.save_pretrained(drive_path)\n",
        "    tokenizer.save_pretrained(drive_path)\n",
        "    print(f\"‚úÖ Model training completed and saved in: {drive_path}\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Step 1: Retrieve the Hugging Face token from Colab secrets\n",
        "try:\n",
        "    hf_token = userdata.get('HF_TOKEN')  # Retrieve the secret\n",
        "    print(\"‚úÖ Hugging Face token found!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Hugging Face token not found. Please add it to Colab secrets.\")\n",
        "    raise e\n",
        "\n",
        "# Step 2: Log in to Hugging Face Hub\n",
        "login(token=hf_token)\n",
        "\n",
        "# Step 3: Use Hugging Face models/datasets\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"‚úÖ Hugging Face model and tokenizer loaded successfully!\")\n",
        "!pip install torch torchvision torchaudio\n",
        "\n",
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "\n",
        "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
        "print(torch.cuda.device_count())  # Check number of available GPUs\n",
        "print(torch.cuda.get_device_name(0))  # Display GPU name\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Import Required Libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import transformers\n",
        "\n",
        "# Suppress unnecessary warnings\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "#  Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "\n",
        "# Load DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "#  Mount Google Drive for dataset access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Define dataset paths\n",
        "folder_path = \"/content/drive/My Drive/Mini Project\"\n",
        "human_file_path = os.path.join(folder_path, \"HumanDataset.csv\")\n",
        "ai_file_path = os.path.join(folder_path, \"AiDataset.csv\")\n",
        "\n",
        "# Load datasets\n",
        "try:\n",
        "    human_texts = pd.read_csv(human_file_path)\n",
        "    ai_texts = pd.read_csv(ai_file_path)\n",
        "    print(\"‚úÖ Datasets loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå File not found. Please check the file paths in Google Drive.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An error occurred: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Clean dataset column names\n",
        "human_texts.columns = human_texts.columns.str.strip()\n",
        "ai_texts.columns = ai_texts.columns.str.strip()\n",
        "\n",
        "#  Ensure \"text\" column exists\n",
        "if \"text\" not in human_texts.columns or \"text\" not in ai_texts.columns:\n",
        "    raise KeyError(\"‚ùå Column 'text' not found in dataset. Check CSV files.\")\n",
        "\n",
        "# Convert text data and remove NaNs\n",
        "human_texts[\"text\"] = human_texts[\"text\"].astype(str).fillna(\"\")\n",
        "ai_texts[\"text\"] = ai_texts[\"text\"].astype(str).fillna(\"\")\n",
        "\n",
        "#  Assign labels (0 = Human, 1 = AI)\n",
        "human_texts[\"label\"] = 0\n",
        "ai_texts[\"label\"] = 1\n",
        "\n",
        "#  Combine datasets and shuffle\n",
        "df = pd.concat([human_texts, ai_texts]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#  Split data into train/test sets (80% train, 20% test)\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "#  Create PyTorch dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, max_length=256):  # Reduce max_length for speed\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "#  Create DataLoaders with smaller batch size\n",
        "train_dataset = TextDataset(train_texts, train_labels, max_length=256)\n",
        "test_dataset = TextDataset(test_texts, test_labels, max_length=256)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # Reduce batch size\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "#  Load pre-trained model or initialize a new one\n",
        "model_path = \"/content/saved_model\"\n",
        "if os.path.exists(model_path):\n",
        "    print(\"‚úÖ Loading pre-trained model...\")\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
        "else:\n",
        "    print(\"üöÄ No trained model found! Initializing a new model.\")\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#  Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#  Training function\n",
        "def train(model, train_loader, optimizer, criterion, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch = {key: val.to(device) for key, val in batch.items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"‚úÖ Epoch {epoch+1} completed | Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    #  Save model after training\n",
        "    model.save_pretrained(model_path)\n",
        "    tokenizer.save_pretrained(model_path)\n",
        "    print(\"‚úÖ Model training completed and saved successfully!\")\n",
        "\n",
        "#  Evaluation function\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations for efficiency\n",
        "        for batch in test_loader:\n",
        "            batch = {key: val.to(device) for key, val in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "            labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            true_labels.extend(labels)\n",
        "\n",
        "    print(\"‚úÖ Model Accuracy:\", accuracy_score(true_labels, predictions))\n",
        "    print(\"üìä Classification Report:\\n\", classification_report(true_labels, predictions))\n",
        "\n",
        "#  Train the model if no saved model exists\n",
        "if not os.path.exists(model_path):\n",
        "    train(model, train_loader, optimizer, criterion)\n",
        "\n",
        "#  Always evaluate the model\n",
        "evaluate(model, test_loader)\n",
        "\n",
        "#  Prediction function\n",
        "def predict_text(text):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs)\n",
        "        prediction = torch.argmax(output.logits, dim=1).item()\n",
        "\n",
        "    return \"AI-generated\" if prediction == 1 else \"Human-generated\"\n",
        "\n",
        "#  Allow user to enter text for prediction\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter a text to check (or type 'exit' to quit): \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    print(\"üìù Prediction:\", predict_text(user_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fYyfMj62hDO6",
        "outputId": "88c5d733-7d04-4649-fb23-c499b2aaa7e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "                                                text  \\\n",
            "0  These methods are intrinsic explainable and ha...   \n",
            "1  The efficacy of Generative Adversarial Network...   \n",
            "2  The objective was to optimize the neural netwo...   \n",
            "3  Another approach has been proposed by Jaide an...   \n",
            "4  As cyber threats continue to intersect with em...   \n",
            "\n",
            "                           DOI  Label  label  \n",
            "0    10.1109/TITS.2024.3474469    0.0      0  \n",
            "1  10.1109/ACCESS.2024.3493957    0.0      0  \n",
            "2      10.1109/TG.2020.3024160    1.0      1  \n",
            "3  10.1109/TCIAIG.2013.2286295    0.0      0  \n",
            "4  10.1109/ACCESS.2024.3493957    1.0      1  \n",
            "‚úÖ Data preprocessing completed successfully!\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "üöÄ No trained model found! Initializing new model.\n",
            "‚úÖ Model is ready!\n",
            "‚úÖ Hugging Face token found!\n",
            "‚úÖ Hugging Face model and tokenizer loaded successfully!\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "‚úÖ Using device: cuda\n",
            "True\n",
            "1\n",
            "Tesla T4\n",
            "‚úÖ Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Datasets loaded successfully!\n",
            "‚úÖ Loading pre-trained model...\n",
            "‚úÖ Model Accuracy: 0.9090909090909091\n",
            "üìä Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.90       323\n",
            "           1       0.89      0.94      0.91       337\n",
            "\n",
            "    accuracy                           0.91       660\n",
            "   macro avg       0.91      0.91      0.91       660\n",
            "weighted avg       0.91      0.91      0.91       660\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e83ba156c722>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;31m#  Allow user to enter text for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter a text to check (or type 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}